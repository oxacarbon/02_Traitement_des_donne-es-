---
title: "05_Projet_Aerien"
author: "Asta Ouattara"
date: "2025-05-24"
output: pdf_document
---


# Chargement des donnÃ©es du projet 4
```{r}
load("/Users/astaoliviaouattara/Desktop/GITHUB_OXACARBON/Output_Projet_Aerien/04_Projet_Aerien.RData")

```


# Machine learnong et prÃ©diction 

## ğŸŒ³ 1. Arbre de dÃ©cision (CART)
Lâ€™arbre de dÃ©cision est comme un arbre logique qui prend des dÃ©cisions pas Ã  pas.

Ã€ chaque embranchement, il pose une question simple :

Est-ce que lâ€™heure prÃ©vue de dÃ©part est aprÃ¨s 18h ?
Est-ce que le vol dÃ©passe 1000 km ?
Est-ce que câ€™est la compagnie X ?
En suivant ce parcours, il arrive Ã  une conclusion : retard probable ou pas.

âœ”ï¸ Avantage : trÃ¨s facile Ã  lire et Ã  expliquer (câ€™est comme une rÃ¨gle conditionnelle).

âŒ Limite : un arbre seul peut Ãªtre instable (sensibles aux donnÃ©es).

ğŸ“Š UtilitÃ© pour les dÃ©cideurs :

Fournit des rÃ¨gles simples de dÃ©tection de vols Ã  risque.
Permet d'identifier des profils de vols plus souvent en retard.


**Intepretation du principe de l'arbre de decision**
Lâ€™arbre de dÃ©cision fonctionne comme un ensemble de rÃ¨gles conditionnelles que lâ€™on suit pas Ã  pas. Par exemple, le modÃ¨le peut dire :

Si le vol est prÃ©vu aprÃ¨s 18h, et quâ€™il part de lâ€™aÃ©roport JFK, et que la distance est supÃ©rieure Ã  800 km,
â†’ Alors il y a 68 % de chances quâ€™il soit en retard.

Ce modÃ¨le est intuitif et facile Ã  lire, ce qui permet aux Ã©quipes opÃ©rationnelles dâ€™identifier rapidement les profils de vols Ã  risque. Il peut par exemple suggÃ©rer de reprogrammer les vols longs de fin de journÃ©e vers des crÃ©neaux moins sensibles.






ğŸŒ² 2. Random Forest (forÃªt alÃ©atoire)
Une forÃªt alÃ©atoire, câ€™est comme plusieurs arbres de dÃ©cision qui votent ensemble.

Chaque arbre analyse les donnÃ©es un peu diffÃ©remment, puis on prend la majoritÃ©.

Cela permet dâ€™avoir une meilleure robustesse : le modÃ¨le est plus stable et fiable que juste un seul arbre.

Il donne aussi des indicateurs dâ€™importance des variables :

Est-ce que câ€™est surtout la distance ?

Est-ce que lâ€™aÃ©roport de dÃ©part compte plus que la compagnie ?

âœ”ï¸ Avantage : trÃ¨s bon compromis entre prÃ©cision, robustesse, et interprÃ©tabilitÃ©.

ğŸ“Š UtilitÃ© pour les dÃ©cideurs :

Permet de cibler les facteurs clÃ©s de retard.

Sert Ã  prioriser les variables Ã  surveiller : si lâ€™heure ou la compagnie est trÃ¨s importante, on agit dessus.

ğŸ”¥ 3. Boosting (xgboost)
Le boosting, câ€™est comme un entraÃ®neur qui corrige ses erreurs Ã  chaque round.

Le premier modÃ¨le essaie de prÃ©dire les retards, mais il se trompe un peu.

Le second modÃ¨le se concentre sur les erreurs du premier.

Le troisiÃ¨me corrige les erreurs du deuxiÃ¨me.

Et ainsi de suite... jusquâ€™Ã  obtenir un modÃ¨le trÃ¨s puissant, capable de repÃ©rer des interactions complexes entre variables.

âœ”ï¸ Avantage : excellent en prÃ©cision de prÃ©diction.

âŒ Limite : plus dur Ã  expliquer en dÃ©tail (modÃ¨le en "boÃ®te noire").

ğŸ“Š UtilitÃ© pour les dÃ©cideurs :

Permet de prÃ©dire avec trÃ¨s haute prÃ©cision si un vol va Ãªtre en retard.

Sert Ã  dÃ©ployer un systÃ¨me dâ€™alerte automatique, basÃ© sur les prÃ©visions.


## PrÃ©paration des donnÃ©es communes 

ğŸªœ Ã‰tapes dÃ©taillÃ©es :
PrÃ©paration des donnÃ©es

On nettoie le jeu de donnÃ©es pour enlever les lignes manquantes (par exemple, quand dep_delay est NA).

On transforme certaines variables (ex : heure de dÃ©part prÃ©vue â†’ heure entiÃ¨re).

On encode les variables catÃ©gorielles (carrier, origin, dest, month) comme des facteurs car le modÃ¨le en a besoin.

SÃ©paration des donnÃ©es




```{r}
# Chargement des packages
library(nycflights13)
library(dplyr)
library(caret)
library(rpart)
library(randomForest)
library(xgboost)

# Nettoyage et sÃ©lection des variables
flights_clean <- flights %>%
  filter(!is.na(dep_delay), !is.na(air_time), !is.na(distance), !is.na(sched_dep_time)) %>%
  mutate(
    retard_15min = ifelse(dep_delay > 15, 1, 0),
    sched_dep_hour = floor(sched_dep_time / 100),
    carrier = as.factor(carrier),
    origin = as.factor(origin),
    dest = as.factor(dest),
    month = as.factor(month)
  ) %>%
  select(retard_15min, carrier, origin, dest, distance, air_time, sched_dep_hour, month)

```

SÃ©paration des donnÃ©es de test et des donnÃ©es d'apprentissage

On divise en donnÃ©es dâ€™apprentissage (70%) et donnÃ©es de test (30%) avec createDataPartition().
```{r}
# SÃ©paration en train / test
set.seed(123)
train_index <- createDataPartition(flights_clean$retard_15min, p = 0.7, list = FALSE)
train <- flights_clean[train_index, ]
test <- flights_clean[-train_index, ]
```



## Arbre de dÃ©cision CART

Objectif : produire un arbre logique pour prÃ©dire si un vol sera en retard (>15 minutes)

1) Construction de lâ€™arbre
On utilise rpart() pour crÃ©er lâ€™arbre de dÃ©cision 

```{r}
# ModÃ¨le CART
model_cart <- rpart(retard_15min ~ ., data = train, method = "class", cp = 0.001, minsplit = 10)


```

Visualisation de l'arbre de dÃ©cision 

```{r}
library(rpart.plot)
rpart.plot(model_cart)

```



```{r}
table(train$retard_15min)

```


2) PrÃ©diction sur les donnÃ©es test
Le modÃ¨le va â€œsuivre les branchesâ€ et dire pour chaque vol sâ€™il est retardÃ© ou non 

```{r}
# PrÃ©dictions
pred_cart <- predict(model_cart, test, type = "class")

```

3) Ã‰valuation
On compare les prÃ©dictions Ã  la rÃ©alitÃ© avec confusionMatrix() :

```{r}
# Ã‰valuation
confusionMatrix(pred_cart, as.factor(test$retard_15min))

```




## Random Forest 

ğŸ¯ Objectif : combiner plusieurs arbres pour une prÃ©diction plus robuste et prÃ©cise
ğŸªœ Ã‰tapes dÃ©taillÃ©es :
MÃªme prÃ©paration des donnÃ©es que pour lâ€™arbre de dÃ©cision.

ModÃ©lisation



1) On crÃ©e 100 arbres avec randomForest() :


```{r}
train_rf <- train %>% select(-dest)
test_rf <- test %>% select(-dest)


```

construction du modÃ¨le

```{r}
model_rf <- randomForest(as.factor(retard_15min) ~ ., data = train_rf, ntree = 100, importance = TRUE)

```



Importance des variables dans la forÃªt

```{r}
varImpPlot(model_rf)

```

2)  PrÃ©diction Le modÃ¨le fait voter les arbres sur les donnÃ©es de test :

```{r}
# PrÃ©dictions
pred_rf <- predict(model_rf, test_rf)

```

3) Ã‰valuation : On calcule la matrice de confusion :

```{r}
# Ã‰valuation
confusionMatrix(pred_rf, as.factor(test_rf$retard_15min))

```

4) Importance des variables :
On visualise quelles variables expliquent le plus les retards :
```{r}
# Importance des variables
varImpPlot(model_rf)

```


## Boosting : XGboost 

ğŸ¯ Objectif : construire une suite de petits modÃ¨les qui corrigent les erreurs des prÃ©cÃ©dents
ğŸªœ Ã‰tapes dÃ©taillÃ©es :
1)Encodage numÃ©rique
xgboost ne supporte pas directement les facteurs. On convertit les donnÃ©es avec model.matrix() :


```{r}
# PrÃ©paration des donnÃ©es pour xgboost
train_x <- model.matrix(retard_15min ~ . -1, data = train)
train_y <- train$retard_15min

test_x <- model.matrix(retard_15min ~ . -1, data = test)
test_y <- test$retard_15min

```


2) ModÃ©lisation : On construit un modÃ¨le boostÃ© avec 100 itÃ©rations :

```{r}
# ModÃ¨le xgboost
model_xgb <- xgboost(data = train_x, label = train_y, 
                     nrounds = 100, objective = "binary:logistic", verbose = 0)
```


3) PrÃ©diction : Le modÃ¨le donne une probabilitÃ© (entre 0 et 1) :

```{r}
# PrÃ©dictions
pred_xgb_prob <- predict(model_xgb, test_x)
pred_xgb <- ifelse(pred_xgb_prob > 0.5, 1, 0)

```


4) Ã‰valuation : MÃªme principe que pour les autres modÃ¨les :

```{r}
# Ã‰valuation
confusionMatrix(as.factor(pred_xgb), as.factor(test_y))

```



## Choix du modÃ¨le finale

```{r}
install.packages("pROC")  # si ce n'est pas dÃ©jÃ  fait
library(pROC)
library(ggplot2)

```

Assure-toi dâ€™avoir des prÃ©dictions probabilistes pour chaque modÃ¨le
ğŸ”¹ Arbre de dÃ©cision (CART)

```{r}
# PrÃ©dictions probabilistes
proba_cart <- predict(model_cart, test, type = "prob")[,2]  # probabilitÃ© dâ€™avoir retard = 1

```


Random Forest 
```{r}
# Si tu as corrigÃ© la variable 'dest' (cf. message prÃ©cÃ©dent)
proba_rf <- predict(model_rf, test_rf, type = "prob")[,2]

```


Boosting : XGboost

```{r}
# DÃ©jÃ  obtenu dans le modÃ¨le prÃ©cÃ©dent
proba_xgb <- predict(model_xgb, test_x)

```



Courbe ROC

```{r}
# Courbes ROC
roc_cart <- roc(test$retard_15min, proba_cart)
roc_rf <- roc(test_rf$retard_15min, proba_rf)
roc_xgb <- roc(test_y, proba_xgb)

# Affichage des AUC
auc(roc_cart)
auc(roc_rf)
auc(roc_xgb)

```


ReprÃ©sentation graphique 

```{r}
# Data pour ggplot
roc_df <- data.frame(
  fpr = c(1 - roc_cart$specificities,
          1 - roc_rf$specificities,
          1 - roc_xgb$specificities),
  tpr = c(roc_cart$sensitivities,
          roc_rf$sensitivities,
          roc_xgb$sensitivities),
  modÃ¨le = factor(rep(c("CART", "Random Forest", "XGBoost"),
                      times = c(length(roc_cart$sensitivities),
                                length(roc_rf$sensitivities),
                                length(roc_xgb$sensitivities))))
)

# Tracer
ggplot(roc_df, aes(x = fpr, y = tpr, color = modÃ¨le)) +
  geom_line(size = 1) +
  geom_abline(linetype = "dashed", color = "gray") +
  labs(title = "Courbes ROC comparÃ©es",
       x = "Taux de faux positifs (1 - spÃ©cificitÃ©)",
       y = "Taux de vrais positifs (sensibilitÃ©)") +
  theme_minimal()

```

